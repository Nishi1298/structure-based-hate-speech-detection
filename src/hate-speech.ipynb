{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure Based Hate Speech Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "DATA_PATH = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(path):\n",
    "    data = []\n",
    "    with open(path,'r') as file:\n",
    "        data = [x for x in csv.reader(file, delimiter=',')]\n",
    "    return data\n",
    "\n",
    "def getTweets(raw):\n",
    "    #pass\n",
    "    data = [x[6] for x in raw]\n",
    "    return np.array(data)\n",
    "\n",
    "def getClass(raw):\n",
    "    #pass\n",
    "    classes = [x[5] for x in raw]\n",
    "    return np.array(classes)\n",
    "\n",
    "def removePattern(tweet, pattern):\n",
    "    r = re.findall(pattern, tweet)\n",
    "    for x in r:\n",
    "        tweet = re.sub(x, '', tweet)\n",
    "    return tweet\n",
    "\n",
    "def preprocess(data):\n",
    "    cleanData = []\n",
    "    for tweet in data:\n",
    "        tweet = removePattern(tweet, \"@[\\w]*\")\n",
    "        tweet = tweet.replace(\"#\", \"\") # Removing '#' from hashtags\n",
    "        tweet = tweet.replace(\"[^a-zA-Z#]\", \" \") # Removing punctuation and special characters\n",
    "        tweet = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+',\"<URL>\", tweet)\n",
    "        tweet = re.sub(\" +\", \" \", tweet)\n",
    "        tweet = tweet.lower()\n",
    "        tweet = tokenize(tweet)\n",
    "#         print(tweet)\n",
    "        cleanData.append(tweet)\n",
    "    return cleanData\n",
    "\n",
    "def tokenize(text):\n",
    "#     print(text)\n",
    "    return text.split(' ')\n",
    "    #return TweetTokenizer.tokenize(text)\n",
    "\n",
    "def evaluate(target, predicted):\n",
    "    f1 = f1_score(target, predicted, average='weighted')\n",
    "    acc = accuracy_score(target, predicted)\n",
    "    rec = recall_score(target, predicted, average = 'macro')\n",
    "    print(\"F1 score:   \", f1)\n",
    "    print(\"Avg Recall: \", rec)    \n",
    "    print(\"Accuracy:   \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = DATA_PATH + \"labeled_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stopwords = set(stopwords.words(\"english\")) \n",
    "\n",
    "raw = readData(DATA) \n",
    "tweets = getTweets(raw)\n",
    "classes = getClass(raw)\n",
    "tweets = preprocess(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [x for x in tweets]\n",
    "X = np.delete(np.array(X), [0])\n",
    "y = np.delete(classes, [0])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# class LSTMClassifier(nn.Module):\n",
    "    \n",
    "#     def __init__(self, embedding_dim, hidden_dim, output_size, batch_size, num_layers = 1):\n",
    "\n",
    "#         super(LSTMClassifier, self).__init__()\n",
    "        \n",
    "#         self.embedding_dim = embedding_dim\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.output_size = output_size\n",
    "#         self.batch_size = batch_size\n",
    "#         self.num_layers = num_layers\n",
    "        \n",
    "#         # Naive embeddings for testing purposes\n",
    "#         self.embedding = nn.Embedding(1024, embedding_dim)\n",
    "        \n",
    "#         self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers = num_layers)\n",
    "#         self.hidden2out = nn.Linear(hidden_dim, output_size)\n",
    "                \n",
    "#         self.hidden = self.init_hidden()\n",
    "#         self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "#         self.dropout_layer = nn.Dropout(p = 0.2)\n",
    "    \n",
    "#     def init_hidden(self):\n",
    "#          return (autograd.Variable(torch.randn(self.num_layers, self.batch_size, self.hidden_dim)),\n",
    "#                 autograd.Variable(torch.randn(self.num_layers, self.batch_size, self.hidden_dim)))\n",
    "        \n",
    "#     def forward(self, sents, lengths):\n",
    "#         embeds = self.embedding(sents)\n",
    "#         packed_input = pack_padded_sequence(embeds, lengths)\n",
    "        \n",
    "#         lstm_out, self.hidden = self.lstm(packed_input, self.hidden)\n",
    "#         y = self.hidden2out(lstm_out[-1])\n",
    "#         y = self.softmax(y)\n",
    "#         return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LSTMClassifier(128, 32, 2, 1)\n",
    "# loss_function = nn.NLLLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=0.1)\n",
    "# model(sampleT, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
