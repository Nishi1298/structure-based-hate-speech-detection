{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure Based Hate Speech Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "DATA_PATH = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(path):\n",
    "    data = []\n",
    "    with open(path,'r') as file:\n",
    "        data = [x for x in csv.reader(file, delimiter=',')]\n",
    "    return data\n",
    "\n",
    "def getTweets(raw):\n",
    "    #pass\n",
    "    data = [x[6] for x in raw]\n",
    "    return np.array(data)\n",
    "\n",
    "def getClass(raw):\n",
    "    #pass\n",
    "    classes = [x[5] for x in raw]\n",
    "    return np.array(classes)\n",
    "\n",
    "def removePattern(tweet, pattern):\n",
    "    r = re.findall(pattern, tweet)\n",
    "    for x in r:\n",
    "        tweet = re.sub(x, '', tweet)\n",
    "    return tweet\n",
    "\n",
    "def preprocess(data):\n",
    "    cleanData = []\n",
    "    for tweet in data:\n",
    "        tweet = removePattern(tweet, \"@[\\w]*\")\n",
    "        tweet = tweet.replace(\"#\", \"\") # Removing '#' from hashtags\n",
    "        tweet = tweet.replace(\"[^a-zA-Z#]\", \" \") # Removing punctuation and special characters\n",
    "        tweet = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+',\"<URL>\", tweet)\n",
    "        tweet = re.sub(\" +\", \" \", tweet)\n",
    "        tweet = tweet.lower()\n",
    "        tweet = tokenize(tweet)\n",
    "#         print(tweet)\n",
    "        cleanData.append(tweet)\n",
    "    return cleanData\n",
    "\n",
    "def tokenize(text):\n",
    "#     print(text)\n",
    "    return text.split(' ')\n",
    "    #return TweetTokenizer.tokenize(text)\n",
    "\n",
    "def evaluate(target, predicted):\n",
    "    f1 = f1_score(target, predicted, average='weighted')\n",
    "    acc = accuracy_score(target, predicted)\n",
    "    rec = recall_score(target, predicted, average = 'macro')\n",
    "    print(\"F1 score:   \", f1)\n",
    "    print(\"Avg Recall: \", rec)    \n",
    "    print(\"Accuracy:   \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = DATA_PATH + \"labeled_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stopwords = set(stopwords.words(\"english\")) \n",
    "\n",
    "raw = readData(DATA) \n",
    "tweets = getTweets(raw)\n",
    "classes = getClass(raw)\n",
    "tweets = preprocess(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [x for x in tweets]\n",
    "X = np.delete(np.array(X), [0])\n",
    "y = np.delete(classes, [0])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# class LSTMClassifier(nn.Module):\n",
    "    \n",
    "#     def __init__(self, embedding_dim, hidden_dim, output_size, batch_size, num_layers = 1):\n",
    "\n",
    "#         super(LSTMClassifier, self).__init__()\n",
    "        \n",
    "#         self.embedding_dim = embedding_dim\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.output_size = output_size\n",
    "#         self.batch_size = batch_size\n",
    "#         self.num_layers = num_layers\n",
    "        \n",
    "#         # Naive embeddings for testing purposes\n",
    "#         self.embedding = nn.Embedding(1024, embedding_dim)\n",
    "        \n",
    "#         self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers = num_layers)\n",
    "#         self.hidden2out = nn.Linear(hidden_dim, output_size)\n",
    "                \n",
    "#         self.hidden = self.init_hidden()\n",
    "#         self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "#         self.dropout_layer = nn.Dropout(p = 0.2)\n",
    "    \n",
    "#     def init_hidden(self):\n",
    "#          return (autograd.Variable(torch.randn(self.num_layers, self.batch_size, self.hidden_dim)),\n",
    "#                 autograd.Variable(torch.randn(self.num_layers, self.batch_size, self.hidden_dim)))\n",
    "        \n",
    "#     def forward(self, sents, lengths):\n",
    "#         embeds = self.embedding(sents)\n",
    "#         packed_input = pack_padded_sequence(embeds, lengths)\n",
    "        \n",
    "#         lstm_out, self.hidden = self.lstm(packed_input, self.hidden)\n",
    "#         y = self.hidden2out(lstm_out[-1])\n",
    "#         y = self.softmax(y)\n",
    "#         return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LSTMClassifier(128, 32, 2, 1)\n",
    "# loss_function = nn.NLLLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=0.1)\n",
    "# model(X, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, TabularDataset\n",
    "def cust_preprocess(tweet):\n",
    "    tweet = removePattern(tweet, \"@[\\w]*\")\n",
    "    tweet = tweet.replace(\"#\", \"\") # Removing '#' from hashtags\n",
    "    tweet = tweet.replace(\"[^a-zA-Z#]\", \" \") # Removing punctuation and special characters\n",
    "    tweet = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+',\"<URL>\", tweet)\n",
    "    tweet = re.sub(\" +\", \" \", tweet)\n",
    "    tweet = tweet.lower()\n",
    "    tweet = tokenize(tweet)\n",
    "    return tweet\n",
    "TEXT = Field(sequential = True, tokenize = cust_preprocess, lower=True)\n",
    "LABEL = Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_datafields = [(\"id\", None), # we won't be needing the id, so we pass in None as the field\n",
    "                 (\"count\", None),\n",
    "                 (\"hate_speech\", None),\n",
    "                 (\"offensive\", None),\n",
    "                 (\"neither\", None),\n",
    "                 (\"clas\", LABEL),\n",
    "                 (\"tweet\", TEXT),]\n",
    "\n",
    "dt = TabularDataset(\n",
    "               path=DATA_PATH + \"labeled_data.csv\",\n",
    "               format='csv',\n",
    "               skip_header=True, # if your csv header has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
    "               fields=tv_datafields)\n",
    "trn, dev,tst = dt.split([0.8,0.1,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 7548),\n",
       " ('rt', 6087),\n",
       " (':', 5941),\n",
       " ('i', 5800),\n",
       " ('the', 5711),\n",
       " ('bitch', 5387),\n",
       " ('you', 4561),\n",
       " ('', 4320),\n",
       " ('to', 4235),\n",
       " ('and', 3140)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator, BucketIterator\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_iter, dev_iter = BucketIterator.splits(\n",
    " (trn, dev), # we pass in the datasets we want the iterator to draw data from\n",
    " batch_sizes=(64, 64),\n",
    " device=device, # if you want to use the GPU, specify the GPU number here\n",
    " sort_key=lambda x: len(x.tweet), # the BucketIterator needs to be told what function it should use to group the data.\n",
    " sort_within_batch=False,\n",
    " repeat=False # we pass repeat=False because we want to wrap this Iterator layer.\n",
    ")\n",
    "test_iter = Iterator(tst, batch_size=64, device=device, sort=False, sort_within_batch=False, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class SimpleBiLSTMBaseline(nn.Module):\n",
    "    def __init__(self, hidden_dim, emb_dim=300,\n",
    "                 spatial_dropout=0.05, recurrent_dropout=0.1, num_linear=1):\n",
    "        super().__init__() # don't forget to call this!\n",
    "        self.embedding = nn.Embedding(len(TEXT.vocab), emb_dim)\n",
    "        self.encoder = nn.LSTM(emb_dim, hidden_dim, num_layers=1, dropout=recurrent_dropout)\n",
    "        self.linear_layers = []\n",
    "        for _ in range(num_linear - 1):\n",
    "            self.linear_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.linear_layers = nn.ModuleList(self.linear_layers)\n",
    "        self.predictor = nn.Linear(hidden_dim, 1)\n",
    "    \n",
    "    def forward(self, seq):\n",
    "        hdn, _ = self.encoder(self.embedding(seq))\n",
    "        feature = hdn[-1, :, :]\n",
    "        for layer in self.linear_layers:\n",
    "            feature = layer(feature)\n",
    "        preds = self.predictor(feature).type(torch.float)\n",
    "#         print(preds.size())\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleBiLSTMBaseline(\n",
       "  (embedding): Embedding(31948, 100)\n",
       "  (encoder): LSTM(100, 500, dropout=0.1)\n",
       "  (linear_layers): ModuleList()\n",
       "  (predictor): Linear(in_features=500, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_sz = 100\n",
    "nh = 500\n",
    "nl = 3\n",
    "model = SimpleBiLSTMBaseline(nh, emb_dim=em_sz); model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 137/310 [00:29<00:57,  3.00it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-57d416523bea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#         print(preds.size(), y.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "# opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "opt = optim.SGD(model.parameters(), lr=0.01, weight_decay=0.1)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train() # turn on training mode\n",
    "    for tt in tqdm.tqdm(train_iter): # thanks to our wrapper, we can intuitively iterate over our data!\n",
    "        opt.zero_grad()\n",
    "        x = tt.tweet\n",
    "        y = tt.clas.unsqueeze(-1).type(torch.float)\n",
    "#         print(y, x)\n",
    "#         y = y.reshape(64, 1)\n",
    "        preds = model(x)\n",
    "#         print(preds.size(), y.size())\n",
    "        loss = loss_func(y, preds)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        running_loss += loss.data.item() * x.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(trn)\n",
    "\n",
    "    # calculate the validation loss for this epoch\n",
    "    val_loss = 0.0\n",
    "    model.eval() # turn on evaluation mode\n",
    "    for tt in dev_iter:\n",
    "        x = tt.tweet\n",
    "        y = tt.clas\n",
    "        preds = model(x)\n",
    "        loss = loss_func(y, preds)\n",
    "        val_loss += loss.data[0] * x.size(0)\n",
    "\n",
    "    val_loss /= len(vld)\n",
    "    print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch, epoch_loss, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
